To implement interservice communication, you can choose from different IPC technologies. For example, services can use synchronous request-response‑based communication mechanisms such as HTTP‑based REST, gRPC, or Thrift. Alternatively, services can use asynchronous, message‑based communication mechanisms such as AMQP or STOMP. You can also choose from various different message formats. For example, services can use human-readable, text‑based formats such as JSON or XML. Alternatively, services can use a binary format such as Avro or Protocol Buffers.

Configuring services to directly call other services leads to high coupling between services. Instead, we recommend using messaging or event-based communication:

- **Messaging**: When you implement messaging, you remove the need for services to call each other directly. Instead, all services know of a message broker, and they push messages to that broker. The message broker saves these messages in a message queue. Other services can subscribe to the messages that they care about.
- **Event-based communication**: When you implement event-driven processing, communication between services takes place through events that individual services produce. Individual services write their events to a message broker. Services can listen to the events of interest. This pattern keeps services loosely coupled because the events don't include payloads.

In a microservices application, we recommend using asynchronous interservice communication instead of synchronous communication. Request-response is a well-understood architectural pattern, so designing a synchronous API might feel more natural than designing an asynchronous system. Asynchronous communication between services can be implemented using messaging or event-driven communication. Using asynchronous communication provides the following advantages:

- **Loose coupling**: An asynchronous model splits the request–response interaction into two separate messages, one for the request and another one for the response. The consumer of a service initiates the request message and waits for the response, and the service provider waits for request messages to which it replies with response messages. This setup means that the caller doesn't have to wait for the response message.
- **Failure isolation**: The sender can still continue to send messages even if the downstream consumer fails. The consumer picks up the backlog whenever it recovers. This ability is especially useful in a microservices architecture, because each service has its own lifecycle. Synchronous APIs, however, require the downstream service to be available or the operation fails.
- **Responsiveness**: An upstream service can reply faster if it doesn't wait on downstream services. If there is a chain of service dependencies (service A calls B, which calls C, etc.), waiting on synchronous calls can add unacceptable amounts of latency.
- **Flow control**: A message queue acts as a buffer, so that receivers can process messages at their own rate.

However, following are some challenges to using asynchronous messaging effectively:

- **Latency**: If the message broker becomes a bottleneck, end-to-end latency might become high.
- **Overhead in development and testing**: Based on the choice of messaging or event infrastructure, there can be a possibility of having duplicate messages, which makes it difficult to make operations idempotent. It also can be hard to implement and test request-response semantics using asynchronous messaging. You need a way to correlate request and response messages.
- **Throughput**: Asynchronous message handling, either using a central queue or some other mechanism can become a bottleneck in the system. The backend systems, such as queues and downstream consumers, should scale to match the system's throughput requirements.
- **Complicates error handling**: In an asynchronous system, the caller doesn't know if a request was successful or failed, so error handling needs to be handled out of band. This type of system can make it difficult to implement logic like retries or exponential back-offs. Error handling is further complicated if there are multiple chained asynchronous calls that have to all succeed or fail.